{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: \n",
    "\n",
    "This notebook is an updated version of the notebook used in the **hands-on lecture**.\n",
    "\n",
    "The following changes have been made:\n",
    "\n",
    "1. **The 0 values in the Preg column are not treated.**\n",
    "    - In the video, the 0 values in all the columns were replaced by the mean values of the columns. But this might not be the correct approach for all the variables present in the data. For example, the value 0 in the blood pressure, skin thickness, etc. doesn't make sense and that why it is considered to be a missing value. But for the pregnancy column, 0 values are valid and meaningful. Hence, in the updated notebook, we didn't treat the 0 values in the Preg column as missing values.\n",
    "\n",
    "\n",
    "2. **random_state parameter is set in the Logistic Regression model.**\n",
    "    - In the video, the random_state parameter was not set in the Logistic Regression model, which might result in different results in the confusion matrix. In the updated notebook, we have set the random_state value, which will ensure that results do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7b3f8258-662b-424a-9d35-e1fb882c1306",
    "_execution_state": "idle",
    "_uuid": "d677e0853462f88572798ca33d1bbd1af9e1f57e"
   },
   "source": [
    "### Pima Indian Diabetes Analysis\n",
    "\n",
    "We will use logistic regression (correction) to model the \"Pima Indians Diabetes\" data set. This model will predict which people are likely to develop diabetes.\n",
    "\n",
    "\n",
    "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset. Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
    "\n",
    "\n",
    "<b>Data Dictionary</b>:\n",
    "\n",
    "Preg: Number of times pregnant<br>\n",
    "Plas: glucose concentration a 2 hours in an oral glucose tolerance test<br>\n",
    "Pres: blood pressure (mm Hg)<br>\n",
    "Skin: skin fold thickness (mm)<br>\n",
    "test: 2-Hour serum insulin (mu U/ml)<br>\n",
    "mass: BMI (weight in kg/(height in m)^2)<br>\n",
    "pedi: pedigree function<br>\n",
    "age: Age (years)<br>\n",
    "Class: variable (0 or 1) 268 of 768 are 1, the others are 0<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "26dcb635-f956-4672-b097-3419e36b0071",
    "_execution_state": "idle",
    "_uuid": "4e83bf1a41e4fce195fce364fe46049d4c47d61a"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "d6c9c45a-ab99-4724-9f79-3078de45a2c2",
    "_execution_state": "idle",
    "_uuid": "3f1077096bcba840ff0b64c1e3e75373d6f7cb4e"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt       # matplotlib.pyplot plots data\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7e6eecbd-4ed5-48a7-9a4a-f332284941a8",
    "_execution_state": "idle",
    "_uuid": "b67213ded17f98e51f96710ed75b3e30e0188aec"
   },
   "source": [
    "## Load and review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "494c0137-fe90-4a56-8c04-8c0cd312f4e0",
    "_execution_state": "idle",
    "_uuid": "18516319ab9c570974d728eb2fc55e54a7b44855"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pima-indians-diabetes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-96f265be0e38>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pima-indians-diabetes.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pima-indians-diabetes.csv'"
     ]
    }
   ],
   "source": [
    "pdata = pd.read_csv(\"pima-indians-diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e76ccd67-f803-4245-aeda-cba2da84b379",
    "_execution_state": "idle",
    "_uuid": "9c42f7d497d2b92f651a33b58359641c6593a441"
   },
   "outputs": [],
   "source": [
    "pdata.shape # Check number of columns and rows in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "219699a3-5760-4c35-a26d-d7343085fde4",
    "_execution_state": "idle",
    "_uuid": "207cb4511bc2147529219737324a37157d1455d8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdata.head(10) # To check first 5 rows of data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2845e88c-8999-48d2-a94d-cae37473fd05",
    "_execution_state": "idle",
    "_uuid": "95fd5e5d6206cd21a548259734596d46329ace3a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdata.isnull().values.any() # If there are any null values in data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e1e111eb-5bfc-40db-8bab-b5853a91ff3a",
    "_execution_state": "idle",
    "_uuid": "9d141393f14e2a890b425f1533862ac2f03d09af"
   },
   "outputs": [],
   "source": [
    "columns = list(pdata)[0:-1] # Excluding Outcome column which has only \n",
    "pdata[columns].hist(stacked=False, bins=100, figsize=(12,30), layout=(14,2)); \n",
    "# Histogram of first 8 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fb8c4dbe-588a-4c0f-97a6-a38b304482cc",
    "_execution_state": "idle",
    "_uuid": "e54f56a861fdb9d808f3063b011198b7c5e54919"
   },
   "source": [
    "## Identify Correlation in data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5712f277-5723-4fcb-86b0-1b8c84046380",
    "_execution_state": "idle",
    "_uuid": "5e3b3649d189594a1aeb9ca2b8b950a9ba0321d1"
   },
   "outputs": [],
   "source": [
    "pdata.corr() # It will show correlation matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4a9f1746-22c5-4383-bbdd-e938ec7ebc90",
    "_execution_state": "idle",
    "_uuid": "6a1fddb0dccb53dea17420096c7217ed1de39cd3"
   },
   "outputs": [],
   "source": [
    "# However we want to see correlation in graphical representation so below is function for that\n",
    "def plot_corr(df, size=11):\n",
    "    corr = df.corr()\n",
    "    fig, ax = plt.subplots(figsize=(size, size))\n",
    "    ax.matshow(corr)\n",
    "    plt.xticks(range(len(corr.columns)), corr.columns)\n",
    "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    for (i, j), z in np.ndenumerate(corr):\n",
    "        ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2099c84c-c9e8-447f-b5c6-6437486974e4",
    "_execution_state": "idle",
    "_uuid": "3ff91c39eabb645846e0a55db47d7d96f1b74d6e"
   },
   "outputs": [],
   "source": [
    "plot_corr(pdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b51323f3-453b-4309-a443-4e257e9b6660",
    "_execution_state": "idle",
    "_uuid": "cd77693b0a04ea357e78bd8848b80ae848e9770d"
   },
   "source": [
    "In above plot yellow colour represents maximum correlation and blue colour represents minimum correlation.\n",
    "We can see none of variable have correlation with any other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(pdata,diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "aa405f3c-38cc-4f3a-a775-ef0d94a067b3",
    "_execution_state": "idle",
    "_uuid": "eff7ef0f7fafb92a1c0d9a93f3a11cef4a92e0f9"
   },
   "source": [
    "## Calculate diabetes ratio of True/False from outcome variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1e7a67ea-7dfc-4c1d-85c1-d299dfeb276e",
    "_execution_state": "idle",
    "_uuid": "63b2386dde054631a479ee491eef64d471e7c887"
   },
   "outputs": [],
   "source": [
    "n_true = len(pdata.loc[pdata['class'] == True])\n",
    "n_false = len(pdata.loc[pdata['class'] == False])\n",
    "print(\"Number of true cases: {0} ({1:2.2f}%)\".format(n_true, (n_true / (n_true + n_false)) * 100 ))\n",
    "print(\"Number of false cases: {0} ({1:2.2f}%)\".format(n_false, (n_false / (n_true + n_false)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3fb2e67c-ad71-4475-af6e-9892508d1b6f",
    "_execution_state": "idle",
    "_uuid": "eb8f05e75cd37f71ce2a9e40d0558eb5538aa08e"
   },
   "source": [
    "So we have 34.90% people in current data set who have diabetes and rest of 65.10% doesn't have diabetes. \n",
    "\n",
    "Its a good distribution True/False cases of diabetes in data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5e39d0b7-2f26-4d26-8a8d-6d0da0e22594",
    "_execution_state": "idle",
    "_uuid": "3c5ea745d170940b3d831b6e128959c87f8c117f"
   },
   "source": [
    "## Spliting the data \n",
    "We will use 70% of data for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5a9250a4-7c26-4770-943e-234568a37be3",
    "_execution_state": "idle",
    "_uuid": "00a1d497bd1fcae2c3500540bede6d2bbf25ab54"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pdata.drop('class',axis=1)     # Predictor feature columns (8 X m)\n",
    "Y = pdata['class']   # Predicted class (1=True, 0=False) (1 X m)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "# 1 is just any random seed number\n",
    "\n",
    "x_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fd533eb9-a891-40de-87d2-7db271681e51",
    "_execution_state": "idle",
    "_uuid": "f667115329e68cfa0015c8c26b57db7104ee3dbb"
   },
   "source": [
    "Lets check split of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "34188146c68af804a7df3cf0e3e33ed79d096985"
   },
   "outputs": [],
   "source": [
    "print(\"{0:0.2f}% data is in training set\".format((len(x_train)/len(pdata.index)) * 100))\n",
    "print(\"{0:0.2f}% data is in test set\".format((len(x_test)/len(pdata.index)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "83fd5fc5ee2f1b7a947e07125a62c6b205d9bdfd"
   },
   "source": [
    "Now lets check diabetes True/False ratio in split data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "eca76e428776a0897acf958ad9791abd06700fe7"
   },
   "outputs": [],
   "source": [
    "print(\"Original Diabetes True Values    : {0} ({1:0.2f}%)\".format(len(pdata.loc[pdata['class'] == 1]), (len(pdata.loc[pdata['class'] == 1])/len(pdata.index)) * 100))\n",
    "print(\"Original Diabetes False Values   : {0} ({1:0.2f}%)\".format(len(pdata.loc[pdata['class'] == 0]), (len(pdata.loc[pdata['class'] == 0])/len(pdata.index)) * 100))\n",
    "print(\"\")\n",
    "print(\"Training Diabetes True Values    : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 1]), (len(y_train[y_train[:] == 1])/len(y_train)) * 100))\n",
    "print(\"Training Diabetes False Values   : {0} ({1:0.2f}%)\".format(len(y_train[y_train[:] == 0]), (len(y_train[y_train[:] == 0])/len(y_train)) * 100))\n",
    "print(\"\")\n",
    "print(\"Test Diabetes True Values        : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 1]), (len(y_test[y_test[:] == 1])/len(y_test)) * 100))\n",
    "print(\"Test Diabetes False Values       : {0} ({1:0.2f}%)\".format(len(y_test[y_test[:] == 0]), (len(y_test[y_test[:] == 0])/len(y_test)) * 100))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "7170e34e9c311bc3f08f02a7ee48ad849f40c006"
   },
   "source": [
    "# Data Preparation\n",
    "\n",
    "### Check hidden missing values \n",
    "\n",
    "As we checked missing values earlier but haven't got any. But there can be lots of entries with 0 values. We must need to take care of those as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "451c63a2f53a84f71f0ef11151b8a1e2ce3b9c9a"
   },
   "source": [
    "### Replace 0s with serial mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "0135f4ba70fef49db752a533488463101e84d2fb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# note that the in the video of this explanation, we have imputed all the zereos. However, this might not be a good approach\n",
    "# as we have other columns where we might need to keep the zeroes as they are. Ex.-pregnancy column\n",
    "\n",
    "# Hence, we will get the imputer to run on the relevant columns only.\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "rep_0 = SimpleImputer(missing_values=0, strategy=\"mean\")\n",
    "cols=['Plas','Pres','skin','test','mass','pedi']\n",
    "\n",
    "x_train[cols] = rep_0.fit_transform(x_train[cols])\n",
    "x_test[cols] = rep_0.transform(x_test[cols])\n",
    "\n",
    "x_test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "da6c25c6f1a37920aa7eba1f5613b76cf50eea1b"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "457aeceed9af02bc850c6c982371b55fe87e4d44"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Fit the model on train\n",
    "model = LogisticRegression(solver=\"liblinear\", random_state=1)\n",
    "model.fit(x_train, y_train)\n",
    "#predict on test\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "\n",
    "coef_df = pd.DataFrame(model.coef_)\n",
    "coef_df['intercept'] = model.intercept_\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_score = model.score(x_test, y_test)\n",
    "print(model_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm=metrics.confusion_matrix(y_test, y_predict, labels=[1, 0])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [\"Actual 1\",\" Actual 0\"]],\n",
    "                  columns = [i for i in [\"Predict 1\",\"Predict 0\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True,fmt='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "47745b3567079b6e08009906a5c5b187d79b9dcd"
   },
   "source": [
    "The confusion matrix\n",
    "\n",
    "True Positives (TP): we correctly predicted that they do have diabetes 50\n",
    "\n",
    "True Negatives (TN): we correctly predicted that they don't have diabetes 131\n",
    "\n",
    "False Positives (FP): we incorrectly predicted that they do have diabetes (a \"Type I error\") 15 Falsely predict positive Type I error\n",
    "\n",
    "False Negatives (FN): we incorrectly predicted that they don't have diabetes (a \"Type II error\") 35 Falsely predict negative Type II error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
